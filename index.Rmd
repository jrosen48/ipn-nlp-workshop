---
title: "An Introduction to Natural Language Processing and Machine Learning"
author: "Joshua M. Rosenberg, Ph.D."
institute: "University of Tennessee, Knoxville"
date: "2021/07/19 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

class: inverse, center, middle

# 1. Introductions

---

## Goals of this workshop

### Over-arching goal:

Get started with applying natural language processing methods in relatively short order through the use of R

### Also: 

This is an opportunity to get to know and learn from one another and to build capacity in science education research to use NLP and do ML

---

## Agenda

1. Introductions (20 min.
2. Brief *R*efresher (20 min.) (10 min.)
3. Overview of core natural language processing (NLP) ideas (10 min.)
4. Trying out NLP analyses, part A (30 min.)
5. Trying out NLP analyses, part B (30 min.)
6. Trying out NLP analyses, part C (30 min.)
7. Learning and doing more (10 min.)
8. Wrap-up (10 min.)

---

## About me

.pull-left[
* Joshua (Josh) Rosenberg, Ph.D.
* Assistant Professor, STEM Education, [University of Tennessee, Knoxville](https://utk.edu/)
* Husband to Katie
* Dad to a toddler
* Research areas:
  * Science education
  * Data science education (a pedagogy)
  * Data science in education (a research approach)
     * Especially Bayesian methods
* Former science teacher in North Carolina
* R user since 2014; developer of many R packages
* Presently PI or Co-PI for three National Science Foundation grants
]

.pull-right[

```{r, echo = FALSE, out.width="100%"}
knitr::include_graphics("img/joro-cycle.jpeg")
```

]

---

## Break-out rooms!

In randomly assigned break-out rooms of ~5-6 people, *starting with whomever has a 
birthday farthest from today*:

- **Introduce yourself** and your position and affiliation
- **Describe the best thing that you have done this summer**
- **Share two words** that capture your attitude toward/beliefs about natural language processing

---

class: inverse, center, middle

# 2. Brief *R*efresher (20 min.)

---

class: inverse, center, middle

# 3. Overview of core NLP ideas (10 min.)

---

## 
- Overview of five foundational NLP ideas (10 min.)
    - Text is everywhere, but it is often much less-structured than the kind of data stored in tables we are used to working with
    - Text can be treated as data
    - Input: A corpus, text with meta-data, typically in a spreadsheet format
    - Key structure: The document-term matrix
    - The creation of a document-term matrix involves processing: tokenizing and optionally removing stopwords, weighting and stemming
    
---

## Defining Machine Learning (ML)

- *Artificial Intelligence (AI)*
.footnote[
[1]  I feel super uncomfortable bringing AI into this, but perhaps it's useful just to be clear about terminology
]
: Simulating human intelligence through the use of computers
- *Machine learning (ML)*: A subset of AI focused on how computers acquire new information/knowledge

This definition leaves a lot of space for a range of approaches to ML

---

## A helpful frame: Supervised & unsupervised

### Supervised ML

- Requires coded data or data with a known outcome
- Uses coded/outcome data to train an algorithm
- Uses that algorithm to **predict the codes/outcomes for new data** (data not used during the training)
- Can take the form of a *classification* (predicting a dichotomous or categorical outcome) or a *regression* (predicting a continuous outcome)
- Algorithms include:
  - [Linear regression (really!)](https://web.stanford.edu/~hastie/ElemStatLearn/)
  - Logistic regression
  - Decision tree
  - Support Vector Machine

---

## What kind of coded data?

> Want to detect spam? Get samples of spam messages. Want to forecast stocks? Find the price history. Want to find out user preferences? Parse their activities on Facebook (no, Mark, stop collecting it, enough!) (from [ML for Everyone](https://vas3k.com/blog/machine_learning/))

In science education:

- Assessment data (e.g., [1](https://link.springer.com/article/10.1007/s10956-020-09895-9))
- Data from log files ("trace data") (e.g., [1](https://www.tandfonline.com/doi/full/10.1080/10508406.2013.837391?casa_token=-8Fm2KCFJ30AAAAA%3Altbc8Y8ci_z-uLJx4se9tgvru9mzm3yqCTFi12ndJ5uM6RDl5YJGG6_4KpUgIK5BYa_Ildeh2qogoQ))
- Open-ended written (text) responses (e.g., [1](https://link.springer.com/article/10.1007/s10956-020-09889-7), [2](https://doi.org/10.1007/s11423-020-09761-w))
- Achievement data (i.e., end-of-course grades) (e.g., [1](https://link.springer.com/article/10.1007/s10956-020-09888-8), [2](https://search.proquest.com/docview/2343734516?pq-origsite=gscholar&fromopenview=true))

What else?
- Drawings/diagrammatic models
- Data collected for formative purposes (i.e., exit tickets)
- ???

---

## How is this different from regression?

The _aim_ is different, the algorithms and methods of estimation are not (or, are differences in degree, rather than in kind).

In a linear regression, our aim is to estimate parameters, such as $\beta_0$ (intercept) and $\beta_1$ (slope), and to make inferences about them that are not biased by our particular sample.

In an ML approach, we can use the same linear regression model, but with a goal other than making unbiased inferences about the $\beta$ parameters:

<h4><center>In supervised ML, our goal is to minimize the difference between a known $y$ and our predictions, $\hat{y}$</center></h3>

---

## So, how is this really different?

This _predictive goal_ means that we can do things differently:

- Multicollinearity is not an issue because we do not care to make inferences about parameters
- Because interpreting specific parameters is less of an interest, we can use a great deal more predictors
- We focus not on $R^2$ as a metric, but, instead, how accurately a _trained_ model can predict the values in _test_ data
- We can make our models very complex (but may wish to "regularize" coefficients that are small so that their values are near-zero or are zero):
  - Ridge models (can set parameters near to zero)
  - Lasso models (can set parameters to zero)
  - Elastic net models (can balance between ridge and lasso models)

---

## Okay, _really_ complex

- Okay, _really_ complex:
  - Neural networks
  - Deep networks
- And, some models can take a different form than familiar regressions:
  - *k*-nearest neighbors
  - Decision trees (and their extensions of bagged and random forests)
- Last, the modeling process can look different:
  - Ensemble models that combine or improve on ("boosting") the predictions of individual models

---

## A helpful frame: Supervised & unsupervised

### Unsupervised ML

- Does not require coded data; one way to think about unsupervised ML is that its purpose is to discover codes/labels
- Is used to discover groups among observations/cases or to summarize across variables
- Can be used in an _exploratory mode_ (see [Nelson, 2020](https://journals.sagepub.com/doi/full/10.1177/0049124118769114?casa_token=EV5XH31qbyAAAAAA%3AFg09JQ1XHOOzlxYT2SSJ06vZv0jG-s4Qfz8oDIQwh2jrZ-jrHNr7xZYL2FwnZtZiokhPalvV1RL2Bw)) 
- **Warning**: The results of unsupervised ML _cannot_ directly be used to provide codes/outcomes for supervised ML techniques 
- Can work with both continuous and dichotomous or categorical variables
- Algorithms include:
  - Cluster analysis
  - [Principle Components Analysis (really!)](https://web.stanford.edu/~hastie/ElemStatLearn/)
  - Latent Dirichlet Allocation (topic modeling)

---

## What technique should I choose?

Do you have coded data or data with a known outcome -- let's say about science students -- and, do you want to:

- _Predict_ how other students with similar data (but without a known outcome) perform?
- _Scale_ coding that you have done for a sample of data to a larger sample?
- _Provide timely or instantaneous feedback_, like in many learning analytics systems?

<h4><center>Supervised methods may be your best bet</center></h4>

Do you not yet have codes/outcomes -- and do you want to?

- _Achieve a starting point_ for qualitative coding, perhaps in a ["computational grounded theory"](https://journals.sagepub.com/doi/full/10.1177/0049124117729703) mode?
- _Discover groups or patterns in your data_ that may be of interest?
- _Reduce the number of variables in your dataset_ to a smaller, but perhaps nearly as explanatory/predictive - set of variables?

<h4><center>Unsupervised methods may be helpful</center></h4>

---

class: inverse, center, middle

# 4. Trying out NLP analyses, part A (30 min.)

---

- Term frequencies
- Term co-occurrences (10 min.) 
- Dictionary-based analyses (10 min.)

## In break-out rooms

Using the file `try-it-out-part-a.R`, work to answer one or more of the following questions:

- How well does our model perform when we _add_ the gradebook or discussion predictors?
- What should we take away from this model and analysis, in general?

Let's head over to the [Learning Lab in RStudior Cloud](https://rstudio.cloud/spaces/140247/project/2510028)!

Add to this slide: https://docs.google.com/presentation/d/1UA_jXyXSq2k5GnXBtlB-a1_Wo0xz1oLR46luo2YoblM/edit?usp=sharing
---

class: inverse, center, middle

# 5. Trying out NLP analyses, part B (30 min.)

---

- Topic models (20 min.)

## In break-out rooms

Using the file `try-it-out-part-b.R`, work to answer one or more of the following questions:

- How well does our model perform when we _add_ the gradebook or discussion predictors?
- What should we take away from this model and analysis, in general?

Let's head over to the [Learning Lab in RStudior Cloud](https://rstudio.cloud/spaces/140247/project/2510028)!

Add to this slide: https://docs.google.com/presentation/d/1UA_jXyXSq2k5GnXBtlB-a1_Wo0xz1oLR46luo2YoblM/edit?usp=sharing

---

class: inverse, center, middle

# 6. Trying out NLP analyses, part C (30 min.)

---

- Supervised machine learning models (20 min.)

## In break-out rooms

Using the file `try-it-out-part-b.R`, work to answer one or more of the following questions:

- How well does our model perform when we _add_ the gradebook or discussion predictors?
- What should we take away from this model and analysis, in general?

Let's head over to the [Learning Lab in RStudior Cloud](https://rstudio.cloud/spaces/140247/project/2510028)!

Add to this slide: https://docs.google.com/presentation/d/1UA_jXyXSq2k5GnXBtlB-a1_Wo0xz1oLR46luo2YoblM/edit?usp=sharing

---
class: inverse, center, middle

# 7. Learning and doing more



## Learning more

- [tidymodels](https://www.tidymodels.org/)
- [Hands-on Machine Learning With R](https://bradleyboehmke.github.io/HOML/)
- [Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/)
- [Learning to Teach Machines to Learn](https://alison.rbind.io/post/2019-12-23-learning-to-teach-machines-to-learn/)
- [Julia Silge's blog](https://juliasilge.com/blog/)

---

## Recommendations

- Start with a problem you are facing
- Use a simple algorithm that you can understand and troubleshoot
- Be mindful of your R code; small issues (with names!) can cause difficulties
- Share and receive feedback
- Explore the variety of ways you can use machine learning; we are deciding as a field how machine learning will (or will not) make a difference in our work
- It _will be really hard at first_; you can do this!

---

class: inverse, center, middle

# 8. Wrap-up

---

class: center, middle

## Thank you and contact information
Stay in touch!

Joshua Rosenberg  
jmrosenberg@utk.edu  
http://joshuamrosenberg.com/  
@jrosenberg6432  

Slides created via the R package [xaringan](https://github.com/yihui/xaringan)
